## Hive簡介

Hive是Facebook開源的一款基於Hadoop的資料倉庫工具，是目前應用最廣泛的大資料處理解決方案，它能將SQL查詢轉變為 MapReduce（Google提出的一個軟體架構，用於大規模資料集的並行運算）任務，對SQL提供了完美的支援，能夠非常方便的實現大資料統計。

<img src="https://gitee.com/jackfrued/mypic/raw/master/20220210080608.png">

> **說明**：可以透過<https://www.edureka.co/blog/hadoop-ecosystem>來了解Hadoop生態圈。

如果要簡單的介紹Hive，那麼以下兩點是其核心：

1. 把HDFS中結構化的資料對映成表。
2. 透過把Hive-SQL進行解析和轉換，最終生成一系列基於Hadoop的MapReduce任務/Spark任務，透過執行這些任務完成對資料的處理。也就是說，即便不學習Java、Scala這樣的程式語言，一樣可以實現對資料的處理。

Hive和傳統關係型資料庫的對比如下表所示。

|          | Hive              | RDBMS        |
| -------- | ----------------- | ------------ |
| 查詢語言 | HQL               | SQL          |
| 儲存資料 | HDFS              | 本地檔案系統 |
| 執行方式 | MapReduce / Spark | Executor     |
| 執行延遲 | 高                | 低           |
| 資料規模 | 大                | 小           |

### 準備工作

1. 搭建如下圖所示的大資料平臺。

    ![bigdata-basic-env](https://gitee.com/jackfrued/mypic/raw/master/20220210080638.png)

2. 透過Client節點訪問大資料平臺。

    ![bigdata-vpc](https://gitee.com/jackfrued/mypic/raw/master/20220210080655.png)

3. 建立檔案Hadoop的檔案系統。

    ```Shell
    hadoop fs -mkdir /data
    hadoop fs -chmod g+w /data
    ```

4. 將準備好的資料檔案複製到Hadoop檔案系統中。

    ```Shell
    hadoop fs -put /home/ubuntu/data/* /data
    ```

### 建立/刪除資料庫

建立。

```SQL
create database if not exists demo;
```

或

```Shell
hive -e "create database demo;"
```

刪除。

```SQL
drop database if exists demo;
```

切換。

```SQL
use demo;
```

### 資料型別

Hive的資料型別如下所示。

基本資料型別。

| 資料型別  | 佔用空間 | 支援版本 |
| --------- | -------- | -------- |
| tinyint   | 1-Byte   |          |
| smallint  | 2-Byte   |          |
| int       | 4-Byte   |          |
| bigint    | 8-Byte   |          |
| boolean   |          |          |
| float     | 4-Byte   |          |
| double    | 8-Byte   |          |
| string    |          |          |
| binary    |          | 0.8版本  |
| timestamp |          | 0.8版本  |
| decimal   |          | 0.11版本 |
| char      |          | 0.13版本 |
| varchar   |          | 0.12版本 |
| date      |          | 0.12版本 |

複雜資料型別。

| 資料型別 | 描述                     | 例子                                          |
| -------- | ------------------------ | --------------------------------------------- |
| struct   | 和C語言中的結構體類似    | `struct<first_name:string, last_name:string>` |
| map      | 由鍵值對構成的元素的集合 | `map<string,int>`                             |
| array    | 具有相同型別的變數的容器 | `array<string>`                               |

### 建立和使用表

1. 建立內部表。

    ```SQL
    create table if not exists user_info 
    (
    user_id string,
    user_name string, 
    sex string,
    age int,
    city string,
    firstactivetime string,
    level int,
    extra1 string,
    extra2 map<string,string>
    )
    row format delimited fields terminated by '\t'
    collection items terminated by ','
    map keys terminated by ':'
    lines terminated by '\n'
    stored as textfile;
    ```

2. 載入資料。

    ```SQL
    load data local inpath '/home/ubuntu/data/user_info/user_info.txt' overwrite into table user_info;
    ```

    或

    ```SQL
    load data inpath '/data/user_info/user_info.txt' overwrite into table user_info;
    ```

3. 建立分割槽表。

    ```SQL
    create table if not exists user_trade 
    (
    user_name string,
    piece int,
    price double,
    pay_amount double,
    goods_category string,
    pay_time bigint
    )  
    partitioned by (dt string)
    row format delimited fields terminated by '\t';
    ```

4. 設定動態分割槽。

    ```SQL
    set hive.exec.dynamic.partition=true;
    set hive.exec.dynamic.partition.mode=nonstrict;
    set hive.exec.max.dynamic.partitions=10000;
    set hive.exec.max.dynamic.partitions.pernode=10000;
    ```

5. 複製資料（Shell命令）。

    ```Shell
    hdfs dfs -put /home/ubuntu/data/user_trade/* /user/hive/warehouse/demo.db/user_trade
    ```

6. 修復分割槽表。

    ```SQL
    msck repair table user_trade;
    ```

### 查詢

#### 基本語法

```SQL
select user_name from user_info where city='beijing' and sex='female' limit 10;
select user_name, piece, pay_amount from user_trade where dt='2019-03-24' and goods_category='food';
```

#### group by

```SQL
-- 查詢2019年1月到4月，每個品類有多少人購買，累計金額是多少
select goods_category, count(distinct user_name) as user_num, sum(pay_amount) as total from user_trade where dt between '2019-01-01' and '2019-04-30' group by goods_category;
```

```SQL
-- 查詢2019年4月支付金額超過5萬元的使用者
select user_name, sum(pay_amount) as total from user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name having sum(pay_amount) > 50000;
```

#### order by

```SQL
-- 查詢2019年4月支付金額最多的使用者前5名
select user_name, sum(pay_amount) as total from user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name order by total desc limit 5;
```

#### 常用函式

1. `from_unixtime`：將時間戳轉換成日期
2. `unix_timestamp`：將日期轉換成時間戳
3. `datediff`：計算兩個日期的時間差
4. `if`：根據條件返回不同的值
5. `substr`：字串取子串
6. `get_json_object`：從JSON字串中取出指定的`key`對應的`value`，如：`get_json_object(info, '$.first_name')`。

