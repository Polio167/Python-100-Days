## Python中的併發程式設計-3

爬蟲是典型的 I/O 密集型任務，I/O 密集型任務的特點就是程式會經常性的因為 I/O 操作而進入阻塞狀態，比如我們之前使用`requests`獲取頁面程式碼或二進位制內容，發出一個請求之後，程式必須要等待網站返回響應之後才能繼續執行，如果目標網站不是很給力或者網路狀況不是很理想，那麼等待響應的時間可能會很久，而在這個過程中整個程式是一直阻塞在那裡，沒有做任何的事情。透過前面的課程，我們已經知道了可以透過多執行緒的方式為爬蟲提速，使用多執行緒的本質就是，當一個執行緒阻塞的時候，程式還有其他的執行緒可以繼續運轉，因此整個程式就不會在阻塞和等待中浪費了大量的時間。

事實上，還有一種非常適合 I/O 密集型任務的併發程式設計方式，我們稱之為非同步程式設計，你也可以將它稱為非同步 I/O。這種方式並不需要啟動多個執行緒或多個程序來實現併發，它是透過多個子程式相互協作的方式來提升 CPU 的利用率，解決了 I/O 密集型任務 CPU  利用率很低的問題，我一般將這種方式稱為“協作式併發”。這裡，我不打算探討作業系統的各種 I/O 模式，因為這對很多讀者來說都太過抽象；但是我們得先丟擲兩組概念給大家，一組叫做“阻塞”和“非阻塞”，一組叫做“同步”和“非同步”。

### 基本概念

#### 阻塞

阻塞狀態指程式未得到所需計算資源時被掛起的狀態。程式在等待某個操作完成期間，自身無法繼續處理其他的事情，則稱該程式在該操作上是阻塞的。阻塞隨時都可能發生，最典型的就是 I/O 中斷（包括網路 I/O 、磁碟 I/O 、使用者輸入等）、休眠操作、等待某個執行緒執行結束，甚至包括在 CPU 切換上下文時，程式都無法真正的執行，這就是所謂的阻塞。

#### 非阻塞

程式在等待某操作過程中，自身不被阻塞，可以繼續處理其他的事情，則稱該程式在該操作上是非阻塞的。非阻塞並不是在任何程式級別、任何情況下都可以存在的。僅當程式封裝的級別可以囊括獨立的子程式單元時，它才可能存在非阻塞狀態。顯然，某個操作的阻塞可能會導程式耗時以及效率低下，所以我們會希望把它變成非阻塞的。

#### 同步

不同程式單元為了完成某個任務，在執行過程中需靠某種通訊方式以協調一致，我們稱這些程式單元是同步執行的。例如前面講過的給銀行賬戶存錢的操作，我們在程式碼中使用了“鎖”作為通訊訊號，讓多個存錢操作強制排隊順序執行，這就是所謂的同步。

#### 非同步

不同程式單元在執行過程中無需通訊協調，也能夠完成一個任務，這種方式我們就稱之為非同步。例如，使用爬蟲下載頁面時，排程程式呼叫下載程式後，即可排程其他任務，而無需與該下載任務保持通訊以協調行為。不同網頁的下載、儲存等操作都是不相關的，也無需相互通知協調。很顯然，非同步操作的完成時刻和先後順序並不能確定。

很多人都不太能準確的把握這幾個概念，這裡我們簡單的總結一下，同步與非同步的關注點是**訊息通訊機制**，最終表現出來的是“有序”和“無序”的區別；阻塞和非阻塞的關注點是**程式在等待訊息時狀態**，最終表現出來的是程式在等待時能不能做點別的。如果想深入理解這些內容，推薦大家閱讀經典著作[《UNIX網路程式設計》](https://item.jd.com/11880047.html)，這本書非常的贊。

### 生成器和協程

前面我們說過，非同步程式設計是一種“協作式併發”，即透過多個子程式相互協作的方式提升 CPU 的利用率，從而減少程式在阻塞和等待中浪費的時間，最終達到併發的效果。我們可以將多個相互協作的子程式稱為“協程”，它是實現非同步程式設計的關鍵。在介紹協程之前，我們先透過下面的程式碼，看看什麼是生成器。

```Python
def fib(max_count):
    a, b = 0, 1
    for _ in range(max_count):
        a, b = b, a + b
        yield a
```

上面我們編寫了一個生成斐波那契數列的生成器，呼叫上面的`fib`函式並不是執行該函式獲得返回值，因為`fib`函式中有一個特殊的關鍵字`yield`。這個關鍵字使得`fib`函式跟普通的函式有些區別，呼叫該函式會得到一個生成器物件，我們可以透過下面的程式碼來驗證這一點。

```Python
gen_obj = fib(20)
print(gen_obj)
```

輸出：

```
<generator object fib at 0x106daee40>
```

我們可以使用內建函式`next`從生成器物件中獲取斐波那契數列的值，也可以透過`for-in`迴圈對生成器能夠提供的值進行遍歷，程式碼如下所示。

```Python
for value in gen_obj:
    print(value)
```

生成器經過預啟用，就是一個協程，它可以跟其他子程式協作。

```Python
def calc_average():
    total, counter = 0, 0
    avg_value = None
    while True:
        curr_value = yield avg_value
        total += curr_value
        counter += 1
        avg_value = total / counter


def main():
    obj = calc_average()
    # 生成器預啟用
    obj.send(None)
    for _ in range(5):
        print(obj.send(float(input())))


if __name__ == '__main__':
    main()
```

上面的`main`函式首先透過生成器物件的`send`方法傳送一個`None`值來將其啟用為協程，也可以透過`next(obj)`達到同樣的效果。接下來，協程物件會接收`main`函式傳送的資料併產出（`yield`）資料的平均值。透過上面的例子，不知道大家是否看出兩段子程式是怎麼“協作”的。

### 非同步函式

Python 3.5版本中，引入了兩個非常有意思的元素，一個叫`async`，一個叫`await`，它們在Python 3.7版本中成為了正式的關鍵字。透過這兩個關鍵字，可以簡化協程程式碼的編寫，可以用更為簡單的方式讓多個子程式很好的協作起來。我們透過一個例子來加以說明，請大家先看看下面的程式碼。

```Python
import time


def display(num):
    time.sleep(1)
    print(num)


def main():
    start = time.time()
    for i in range(1, 10):
        display(i)
    end = time.time()
    print(f'{end - start:.3f}秒')


if __name__ == '__main__':
    main()
```

上面的程式碼每次執行都會依次輸出`1`到`9`的數字，每個間隔`1`秒鐘，整個程式碼需要執行大概需要`9`秒多的時間，這一點我相信大家都能看懂。不知道大家是否意識到，這段程式碼就是以同步和阻塞的方式執行的，同步可以從程式碼的輸出看出來，而阻塞是指在呼叫`display`函式發生休眠時，整個程式碼的其他部分都不能繼續執行，必須等待休眠結束。

接下來，我們嘗試用非同步的方式改寫上面的程式碼，讓`display`函式以非同步的方式運轉。

```Python
import asyncio
import time


async def display(num):
    await asyncio.sleep(1)
    print(num)


def main():
    start = time.time()
    objs = [display(i) for i in range(1, 10)]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(objs))
    loop.close()
    end = time.time()
    print(f'{end - start:.3f}秒')


if __name__ == '__main__':
    main()
```

Python 中的`asyncio`模組提供了對非同步 I/O 的支援。上面的程式碼中，我們首先在`display`函式前面加上了`async`關鍵字使其變成一個非同步函式，呼叫非同步函式不會執行函式體而是獲得一個協程物件。我們將`display`函式中的`time.sleep(1)`修改為`await asyncio.sleep(1)`，二者的區別在於，後者不會讓整個程式碼陷入阻塞，因為`await`操作會讓其他協作的子程式有獲得 CPU 資源而得以運轉的機會。為了讓這些子程式可以協作起來，我們需要將他們放到一個事件迴圈（實現訊息分派傳遞的系統）上，因為**當協程遭遇 I/O 操作阻塞時，就會到事件迴圈中監聽 I/O 操作是否完成，並註冊自身的上下文以及自身的喚醒函式（以便恢復執行），之後該協程就變為阻塞狀態**。上面的第12行程式碼建立了`9`個協程物件並放到一個列表中，第13行程式碼透過`asyncio`模組的`get_event_loop`函式獲得了系統的事件迴圈，第14行透過`asyncio`模組的`run_until_complete`函式將協程物件掛載到事件迴圈上。執行上面的程式碼會發現，`9`個分別會阻塞`1`秒鐘的協程總共只阻塞了約`1`秒種的時間，因為**阻塞的協程物件會放棄對 CPU 的佔有而不是讓 CPU 處於閒置狀態，這種方式大大的提升了 CPU 的利用率**。而且我們還會注意到，數字並不是按照從`1`到`9`的順序列印輸出的，這正是我們想要的結果，說明它們是**非同步執行**的。對於爬蟲這樣的 I/O 密集型任務來說，這種協作式併發在很多場景下是比使用多執行緒更好的選擇，因為這種做法減少了管理和維護多個執行緒以及多個執行緒切換所帶來的開銷。

### aiohttp庫

我們之前使用的`requests`三方庫並不支援非同步 I/O，如果希望使用非同步 I/O 的方式來加速爬蟲程式碼的執行，我們可以安裝和使用名為`aiohttp`的三方庫。

安裝`aiohttp`。

```Bash
pip install aiohttp
```

下面的程式碼使用`aiohttp`抓取了`10`個網站的首頁並解析出它們的標題。

```Python
import asyncio
import re

import aiohttp
from aiohttp import ClientSession

TITLE_PATTERN = re.compile(r'<title.*?>(.*?)</title>', re.DOTALL)


async def fetch_page_title(url):
    async with aiohttp.ClientSession(headers={
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36',
    }) as session:  # type: ClientSession
        async with session.get(url, ssl=False) as resp:
            if resp.status == 200:
                html_code = await resp.text()
                matcher = TITLE_PATTERN.search(html_code)
                title = matcher.group(1).strip()
                print(title)


def main():
    urls = [
        'https://www.python.org/',
        'https://www.jd.com/',
        'https://www.baidu.com/',
        'https://www.taobao.com/',
        'https://git-scm.com/',
        'https://www.sohu.com/',
        'https://gitee.com/',
        'https://www.amazon.com/',
        'https://www.usa.gov/',
        'https://www.nasa.gov/'
    ]
    objs = [fetch_page_title(url) for url in urls]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(objs))
    loop.close()


if __name__ == '__main__':
    main()
```

輸出：

```
京東(JD.COM)-正品低價、品質保障、配送及時、輕鬆購物！
搜狐
淘寶網 - 淘！我喜歡
百度一下，你就知道
Gitee - 基於 Git 的程式碼託管和研發協作平臺
Git
NASA
Official Guide to Government Information and Services   &#124; USAGov
Amazon.com. Spend less. Smile more.
Welcome to Python.org
```

從上面的輸出可以看出，網站首頁標題的輸出順序跟它們的 URL 在列表中的順序沒有關係。程式碼的第11行到第13行建立了`ClientSession`物件，透過它的`get`方法可以向指定的 URL 發起請求，如第14行所示，跟`requests`中的`Session`物件並沒有本質區別，唯一的區別是這裡使用了非同步上下文。程式碼第16行的`await`會讓因為 I/O 操作阻塞的子程式放棄對 CPU 的佔用，這使得其他的子程式可以運轉起來去抓取頁面。程式碼的第17行和第18行使用了正則表示式捕獲組操作解析網頁標題。`fetch_page_title`是一個被`async`關鍵字修飾的非同步函式，呼叫該函式會獲得協程物件，如程式碼第35行所示。後面的程式碼跟之前的例子沒有什麼區別，相信大家能夠理解。

大家可以嘗試將`aiohttp`換回到`requests`，看看不使用非同步 I/O 也不使用多執行緒，到底和上面的程式碼有什麼區別，相信透過這樣的對比，大家能夠更深刻的理解我們之前強調的幾個概念：同步和非同步，阻塞和非阻塞。
